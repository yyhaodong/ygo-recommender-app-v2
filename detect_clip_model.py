# detect_clip_model.py
import json, sys
import numpy as np
import torch, open_clip
from PIL import Image
import requests
from io import BytesIO

# ---------- 1) è½½å…¥ä½ çš„å‘é‡ ----------
EMB_PATH = "art_embs.npz"     # å¦‚åœ¨åˆ«å¤„è¯·æ”¹è·¯å¾„
KEY = "data"                  # ä½ çš„ npz é”®
embs = np.load(EMB_PATH)[KEY].astype(np.float32)
embs = embs / np.linalg.norm(embs, axis=1, keepdims=True)
print(f"âœ… emb shape = {embs.shape}  (dim={embs.shape[1]})")

# ---------- 2) å‡†å¤‡ä¸€å¼ æµ‹è¯•å›¾ ----------
IMG_URL = "https://images.ygoprodeck.com/images/cards/89631139.jpg"
img = Image.open(BytesIO(requests.get(IMG_URL).content)).convert("RGB")

# ---------- 3) å¤‡é€‰æ¨¡å‹åˆ—è¡¨ï¼ˆå¯æŒ‰éœ€å¢åˆ ï¼‰ ----------
candidates = [
    ("ViT-B-32", "openai"),
    ("ViT-B-16", "openai"),
    ("ViT-L-14", "openai"),
    ("ViT-L-14", "laion2b_s32b_b82k"),
    ("ViT-H-14", "laion2b_s32b_b79k"),
]

def test_one(name, pre):
    model, _, preprocess = open_clip.create_model_and_transforms(name, pretrained=pre)
    model.eval()
    with torch.no_grad():
        x = preprocess(img).unsqueeze(0)
        feat = model.encode_image(x)
        feat = feat / feat.norm(dim=-1, keepdim=True)
    v = feat.cpu().numpy().astype(np.float32)[0]
    score = float(np.dot(embs, v).max())
    return score

scores = []
for name, pre in candidates:
    print(f"ğŸ” æµ‹è¯• {name:10s} ({pre}) ...", end="")
    try:
        s = test_one(name, pre)
        print(f" max cosine = {s:.4f}")
        scores.append((s, name, pre))
    except Exception as e:
        print(f" å¤±è´¥ï¼š{e}")

if not scores:
    print("âŒ æ²¡æœ‰ä»»ä½•æ¨¡å‹æµ‹è¯•æˆåŠŸã€‚è¯·æ£€æŸ¥ç½‘ç»œæˆ– open_clip å®‰è£…ã€‚")
    sys.exit(1)

best = max(scores, key=lambda x: x[0])
best_score, best_name, best_pre = best

print("\n=== åˆ¤å®šç»“æœ ===")
for s, n, p in sorted(scores, key=lambda x: -x[0]):
    print(f"{n:10s} | {p:22s} | {s:.4f}")
print("\nğŸ‘‰ è¯·æŠŠä¸‹é¢ä¸¤è¡Œç²˜è´´è¿› app.py é¡¶éƒ¨ï¼š")
print(f'MODEL_NAME = "{best_name}"')
print(f'PRETRAINED = "{best_pre}"')

# åŒæ—¶å†™å…¥åˆ° clip_config.jsonï¼Œä¾¿äºåº”ç”¨è‡ªåŠ¨è¯»å–
cfg = {"MODEL_NAME": best_name, "PRETRAINED": best_pre, "score": best_score}
with open("clip_config.json", "w", encoding="utf-8") as f:
    json.dump(cfg, f, ensure_ascii=False, indent=2)
print("\nå·²å†™å…¥ clip_config.jsonï¼š", cfg)
